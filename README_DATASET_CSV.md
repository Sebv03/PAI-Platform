# ğŸ“Š Dataset CSV para Modelo ML

Este documento explica cÃ³mo usar el dataset CSV generado para entrenar el modelo ML.

## ğŸ“¦ Archivo Generado

**Archivo**: `datasets/test_dataset.csv`

**CaracterÃ­sticas**:
- 3,048 registros totales
- 200 estudiantes Ãºnicos
- 10 cursos Ãºnicos
- 80 tareas (8 por curso)
- 74% tasa de entrega
- Notas en escala 1-7

## ğŸš€ CÃ³mo Generar el CSV

Ejecuta el script desde la raÃ­z del proyecto:

```bash
python generate_test_dataset.py
```

Esto crearÃ¡ el archivo `datasets/test_dataset.csv`.

## ğŸ“‹ Estructura del CSV

El CSV contiene las siguientes columnas:

| Columna | DescripciÃ³n | Tipo |
|---------|-------------|------|
| `task_id` | ID de la tarea | int |
| `course_id` | ID del curso | int |
| `student_id` | ID del estudiante | int |
| `task_created_at` | Fecha de creaciÃ³n de la tarea | datetime |
| `due_date` | Fecha lÃ­mite de entrega | datetime |
| `enrollment_date` | Fecha de inscripciÃ³n del estudiante | datetime |
| `submission_id` | ID de la entrega (NaN si no entregÃ³) | float/NaN |
| `submitted_at` | Fecha de entrega (NaN si no entregÃ³) | datetime/NaN |
| `grade` | Nota recibida (NaN si no entregÃ³ o no calificado) | float/NaN |

## ğŸ“ Uso en Google Colab

1. **Subir el CSV a Colab**:
   ```python
   from google.colab import files
   uploaded = files.upload()  # Selecciona test_dataset.csv
   df = pd.read_csv('test_dataset.csv')
   ```

2. **O cargar desde GitHub**:
   ```python
   url = "https://raw.githubusercontent.com/Sebv03/PAI-Platform/main/datasets/test_dataset.csv"
   df = pd.read_csv(url)
   ```

3. **Seguir la guÃ­a**: `GUIA_COLAB_CON_CSV.md`

## ğŸ“ˆ Datos Generados

### Perfiles de Estudiantes

- **70% Bajo Riesgo**: 
  - Alta tasa de entrega (70-95%)
  - Pocas entregas tardÃ­as (20%)
  - Notas promedio: 4.5-6.5

- **30% Alto Riesgo**:
  - Baja tasa de entrega (30-70%)
  - Muchas entregas tardÃ­as (60%)
  - Notas promedio: 2.5-4.0

### Variable Objetivo

Riesgo alto (1) si:
- Promedio de notas < 4.0 (en escala 1-7), **O**
- Tasa de no entrega > 0.5

## âœ… ValidaciÃ³n

El CSV estÃ¡ listo para usar directamente con:

1. âœ… Feature engineering del proyecto
2. âœ… Entrenamiento del modelo RandomForestClassifier
3. âœ… EvaluaciÃ³n de mÃ©tricas

## ğŸ”„ Regenerar el Dataset

Si necesitas regenerar el dataset con diferentes parÃ¡metros:

1. Edita `generate_test_dataset.py`
2. Modifica los parÃ¡metros:
   ```python
   df = generate_synthetic_data(
       n_students=300,      # MÃ¡s estudiantes
       n_courses=15,        # MÃ¡s cursos
       tasks_per_course=10, # MÃ¡s tareas por curso
       random_seed=42       # Misma semilla = mismos datos
   )
   ```
3. Ejecuta: `python generate_test_dataset.py`

## ğŸ“ Notas

- El dataset usa `random_seed=42` para reproducibilidad
- Las fechas estÃ¡n en formato ISO (YYYY-MM-DD)
- Los valores NaN representan datos faltantes (no entregado, no calificado)
- El CSV estÃ¡ codificado en UTF-8

## ğŸ¯ Resultados Esperados

Con este dataset, el modelo deberÃ­a alcanzar:

- **Accuracy**: ~0.85-0.95
- **Precision**: ~0.85-0.95
- **Recall**: ~0.85-0.95
- **F1-Score**: ~0.85-0.95

Estos resultados son similares a los obtenidos con datos histÃ³ricos reales del proyecto.

---

**Â¡Listo! ğŸ‰ El CSV estÃ¡ preparado para usar en Colab o en el proyecto local.**

